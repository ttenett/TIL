24.01.25
데이터사이언스 스쿨 교재 
https://datascienceschool.net/intro.html

* 선형대수학 : 많은 양의 데이터를 다루기 쉽게 해주는 수학
* 연속적인() 대신할 수 있는 수학 ()<- 수열

# 1장 수학기호
## 1.2 수열과 집합

 - index : SQL이나 프로그래밍적이지 않은 일반적 수의 나열
 - offset index : 이격, 첫번째 데이터로부터 얼마나 떨어져있는지를 나타냄. 첫번째 숫자는 첫번째 데이터와 0만큼 떨어져있어서. 그래서 0
 - 
### 수열
- 수열의 index: 순서, index
- x₁~ xn : n개의 데이터가 있다 


### 집합
- 집합에서의 index: (고유한) id 
- R = realnumber = 실수 = 실제로 존재하는 수 = 이 세상에 존재하는 모든 수 의 집합 
- x ∈ R 
실수집합 R에 포함된 실수 x
- (x₁, x₂) ∈ R*R = (x₁, x₂) ∈ R² 

### 수열의 합과 곱
- ∑ 시그마, 썸 = 합 ← 선형대수에서 많이 쓸

- ∏ 프로덕트, 파이 = 곱 ← 확률에서 많이 씀

# 2장 넘파이(Numpy)로 공부하는 선형대수
## 2.1 데이터와 행렬
### 데이터의 유형
1. 스칼라(Scalar) : 0차원 데이터, 하나의 타깃에 대해서 1종류의 데이터만 수집.
2. 벡터(Vector) : 1차원 데이터, 한 방향으로만 데이터가 증가.
   
   데이터를 모으는 방법 2가지 형식

   - 열 벡터(Colum) : 3명에 대한 키 수집, n개의 표본에 대한 한가지 데이터. **여러개의 타깃에 대한 한 종류**에 대해서 수집. (Pandas로 보면 Series에 해당)
  
   - 행 벡터(Row): 1명에 대해 키/몸무게 수집, **한개의 표본(타깃)에 대한 여러 종류의 데이터**를 수집.

3. 행렬(Matrix) : 2차원 데이터, **여러개의 타깃에 대해서 여러종류의 데이터를 수집**

| | 키 | 몸 | 세로(colum) |
|---|---|---|---|
|A	|180|83	| N |
|B	|162|59	| N |
|C	|175|72	| N |
|가로(row)| M | M |N 개수/ M 종류|


- ### 행렬로 스칼라, 벡터 표현

  - 스칼라 x ∈ R 
  - 벡터  x ∈ Rᴺ 
  - 행렬 x ∈ Rᴺˣᴹ      => N 개수 M 종류

```
[a] ∈ R ¹ˣ¹

    [x₁]
x = [x₂] ∈ R ¹ˣ¹
    [x₃]             

x = [x₁ x₂ x₃] ∈ R ¹ˣ³
```

- ML 에서 특징벡터 (Feauture Vector) => 사이킬러, 탠서플로TF, 파이토치 pytouch -> 절대 스칼라, 벡터로 처리하지 않음. 무조건 Matrix 이상부터 처리.

종류는 1종류를 유지, 개수는 n개로.
- 파이썬에서 열벡터와 행벡터 표기방법
```
    [x₁]   [[x₁]
x = [x₂] => [x₂]
    [x₃]    [x₃]]

x = [x₁ x₂ x₃] => [[x₁ x₂ x₃]]

```

1. Tensor -> 3차원 이상 Data (데이터사이언스 분야에서는 4차원 데이터 자체를 텐서로 부르기도 함. 딥러닝은 3차원이상의 데이터를 가지고 함.)
   대표적인 예시 ) 영상

- 넘파이를 사용한 벡터표현은 참고만. 직접 쓸 일이 없기때문. 사용할때 확인. 데이터와 데이터의 유사도를 확인 가능.


### 전치연산 (transpose)
행과 열을 바꿔주는 것. 
X = [x₁ x₂] n
      m  m

x ᵢ 행 번호(m) ⱼ 열 번호(n)

- xᵢⱼ  =>  xⱼᵢ

- 선형대수에서 벡터는 : 열 벡터!

행렬 x ∈ Rᴺˣᴹ   => xᵀ ∈ Rᴹˣᴺ

  => 벡터를 전치시킨다 = 열벡터를 행벡터로 바꾸는 과정

- 벡터의 전치과정

  > x ∈ Rᴺˣ¹  => xᵀ ∈ R¹ˣᴺ

  : 벡터는 전치가 불가능하다 = 전치를 하나, 하지않으나 똑같음.
여기에서는 열/행벡터 데이터종류가 지금은 상관이 없음. 수학적으로 데이터를 확인해보는 것. 표현식에 대해서만 이해.
모양에 대해서 집중.
```
[x₁]ᵀ
[x₂]  =  [x₁ x₂ x₃]
[x₃]  
```

벡터를 행렬의 형태로 표현하고 이해해야 데이터가 어떻게 바뀌어나가는지 파악하기 쉬워짐.
열벡터와 행벡터간의 차이는 상관이 없음. 왜냐하면 계산을 하기위한 변환이기 때문에 여기서는 의미가 없음. 한종류 데이터를 여러개로 모았네, 여러종류 데이터를 하나로 모았네 같은 의미는 데이터를 정리할때 필요한 개념.
수집해서 분석해야 될 때, 데이터를 쌓아놓아야 할 때의 정의.

지금부터는 계산을 할 것. 행렬과 벡터를 이용해서, 계산에 필요한 방법이라고 보면 됨.

```
                    [r₁ᵀ
X  = [C1, C2, Cₘ]  = r₂ᵀ
                     r₃ᵀ]
```

행렬을 벡터로 표현하는것
열벡터끼리 묶어서 행벡터 , 행벡터를 묶어서 열벡터로 표현가능.
트랜스포즈가 붙으면 무조건 헹벡터 , 안붙어있으면 열벡터

x ∈ Rᴺˣᴹ     X = [x₁ x₂] n
                   m  m

### 특수한 벡터와 행렬
- 영벡터(영행렬) : 열벡터의 모양으로 0이 n개가 있음. => 딥러닝할때 초기값. ex) 초기 바이러스 설정

- 일벡터 : 모든 원소가 1인 행렬. Numpy 에서 브로드캐스팅을 선형대수로 이야기할때 일벡터 사용.
[0]
[0]
[0]

- 정방행렬 : 행과 열의 개수가 똑같음. 정사각형
- 대각행렬 : 주대각방향 (우하향대각선)에만 0이 아닌 값이 차있음. 그외는 모두 0으로 채워짐. 반드시 정방행렬일 필요는 없다.
- 항등행렬 : 모든 대각성분의 값이 1 (주대각방향 값이 모두 1) 그외 0 => 역행렬하면서 다시 얘기
- 대칭행렬 : 전치를 하나, 하지않으나 똑같은 값을 가짐. 원래의 행렬이 고대로 나옴. 무조건 정방행렬만 대칭행렬이 될 수 있음.
  Sᵀ = S
  S ∈ Rᴺˣᴺ

## 2.2 벡터와 행렬의 연산
### 벡터/행렬의 덧셈과 뺄셈
요소별(element-wise) 연산을 할 때는 계산하고자 하는 행렬/벡터 모양이 정확하게 똑같아야 함.

x ∈ Rᴺˣᴹ
y ∈ Rᴺˣᴹ

### ★ 스칼라와 벡터/행렬의 곱셈
벡터 x 또는 행렬 A의 모든 원소에 스칼라값 c를 곱하는것은 벡터x 또는 행렬 A의 모든 원소에 스칼라값 c를 곱하는 것과 같다. 모두 분배.

### 선형조합
벡터들, 행렬들 값에 스칼라값을 곱해주겠다.
모든 벡터나 행렬의 모양이 동일해야 선형조합이 가능!

>> 선형조합을 해도 그 (벡터나 행렬의)크기가 변하지 않는다. 

x₁ x₂ ··· xL ∈ Rᴺ : 벡터들이 모두 N개의 데이터를 가지고 있다 > 벡터들의 크기가 모두 N > 이 벡터들에 선형조합을 걸어도 ∈ Rᴺ
벡터 세로길이 3, 3, 4면 선형조합 성립 X
3, 3, 3으로 같아야 가능함.
c1x1 + c2x2 + c3+x3 ∈ R³

행렬을 선형조합 = 행렬

벡터를 선형조합 = 벡터

- 선형조합
❗벡터나 행렬 각각 앞에 어떤 스칼라값을 곱하고, 이것들을 모두 더하면 = 선형조합

### 벡터와 벡터의 곱셈 
-> 10 중 8,9는 내적을 뜻함.

벡터 x와 벡터 y의 내적값?
xᵀy = 내적 => "ㅓ"

앞쪽에 오는 데이터를 전치시키고, y는 그대로. 앞쪽은 행벡터의 형식, 뒤는 열벡터의 형식. "ㅓ" 자 모양을 그린다.

xᵀy : 이 모양이 보이면 내적을 하는구나 라고 생각하면 됨.

두 벡터를 내적하려면 2가지 조건이 만족되어야 함.
1) 우선 두 벡터의 차원(길이)가 같아야 함
2) 앞의 벡터가 행 벡터이고 뒤의 벡터가 열 벡터여야 한다.


원소 스칼라(x₁)와 스칼라(y₁)를 곱해줌. 각각 모조리 더해주면 됨.

```
                [y₁]
xᵀy = [x₁ x₂ x₃][y₂]  x₁y₁ +···+ xₙyₙ = (수열의 합) i=1,N ∑xᵢyᵢ 
                [y₃]


x ∈ Rᴺˣ¹      xᵀ ∈ R¹ˣᴺ
y ∈ Rᴺˣ¹

xᵀy ∈ R (스칼라)
```
- 벡터와 벡터의 내적 =>  x₁y₁ +···+ xₙyₙ 스칼라끼리의 합이 되므로 > 항상 스칼라 (나중에는 매트릭스가 되기도 함)
  
- 반대로 "ㅏ" 자로 곱할때는? 매트릭스가 됨.
(머신러닝에서 주로 사용되는 기법)

내적을 왜 할까? 정보와 정보의 조합 > 하나의 값으로 구하기 위해. 해석을 할 수 있음. 벡터와 벡터의 조합.

### 가중합
가중치를 곱하고 그걸 합한것

### 가중치(weight)
w(계수벡터) * x벡터 ⇒ wᵀx = xᵀw

가중치 w = 갯수 = 어떤 값 앞에 계수로 붙어있는 것. 미지수 뒤에 붙는 하나의 계수벡터.
갯수 > 커지면 커질수록 최종 가격이 올라감 
벡터안의 원소와 가중치의 값을 내적시킨 결과물.
내적이니 "ㅓ" 자로 곱함. 
x든 w든 어느것이든 앞에올수있음 (T트랜스포즈 가능) 내적의 순서를 바꿔도 변하지 않음.

1) 결과를 **결정**할 때 부가적인 **정보**를 의미
   - 가격을 결정할 수 있는 가격정보(가격표)
구매한 갯수A에 추가적인 정보를 줌. 곱셈이므로 연관성요약.
1) 절대값이 클 수록 결과에 영향을 많이 미친다. → 가중치가 클수록 결과의 변동이 커진다.

ex) 육포 2개 살때보다 츄파츕스 2개사는게 가격 오르는 폭이 작음. 육포보다 결과물에 영향을 덜 미친다. 왜? 가중치가 작으니까. 20개를 사도 육포1개 산거랑 같음. 

⇒ 가중치가 커지면 결과값의 변동도 커짐. 숫자가 (개수가) 조금만 바뀌어도 크게 영향을 미침.

가중치가 작으면 결과물의 영향도 적다. 가중치 크면 결과값의 영향이 많이 간다.

W 계수벡터는 변하지 않음. 언제나 고정.
몇개를 살건지는 매번 다르고 모르니까 x로 둠.
x라는 산 갯수가 바뀌니까 값이 바뀜.

### 유사도
유사도와 내적의 관계. *코사인 유사도
내적을 함으로써 유사도관계를 수치로 확인가능.

v1과 v2의 내적값 3064
v1과 v3의 내적값 1866
내적값이 더 큰 v1과 v2가 더 유사하다!  
내적 결과의 의미파악이 중요하다.

### 선형회귀모형

- 독립변수 x : 서로 영향주지 않음
- 종속변수 y : x에 의해 결정
- 계수, 가중치 : 1500, 2000

y = 1500X(오렌지) + 2000X(사과)
x오렌지, x사과끼리 독립변수

ŷ = 예측값
y = 실제 값

머신러닝 딥러닝은 가중치w와 미지수x로부터 시작함. 사용자가 구매했을때 얼마가 나올지 예측하는 수식을 만들 수 있다.

ŷ = w₁x₁ +···+ wₙxₙ
이 수식은 벡터의 내적으로 나타낼 수 있다.
ŷ = wᵀx

ex)w땅x땅 + w육x육 + w핫x핫 + w츄x츄
= [w1 w2 w3 w4][x₁] = wᵀx
                x₂
                x₃
                
[x₁]ᵀ
[x₂]  =  [x₁ x₂ x₃]
[x₃]