# 1. 데이터 엔지니어링
## 1. 데이터엔지니어링 
 전에는 대기업 위주였으나 스타트업이나 작은 규모의 회사에서도 데이터를 활용하려는 움직임이 늘고 있음. 인프라에 대한 이해가 필수적이게 되고 있다.

- 인프라 sw 1. 설치 2. 데이터 레이크, 웨어하우스, 마트 구성할 수 있어야 함. 서포터의 역할 for DA, DS ,
- 데이터 수집 - 처리 - 저장 - 분석 : 데이터를 이용해서 인사이트를 추출하는 업무의 대부분은 엔지니어링.  처리/저장 (L,W,M) 수집부터 저장까지 엔지니어링파트, 시간이 오래걸림.

### 데이터 엔지니어링의 전망
- 이전에는 구축시스템 가격 비싸고, 데이터용도가 정해져있었고, 수집처가 일정했음. (POST, 게시글에서만 )
- 요즘은 크롤링 또는 원하는곳에서 다운로드 가능.

### 과거의 데이터 아키텍쳐 & 현재
- 데이터의 용도가 정해져있다 : 데이터에 대한 형식, 스키마를 미리 만들어 놓는 것. = RDBMS, CREATE TABLE . 데이터 변동이 별로 x, 효율적이고 정확한 데이터베이스 모델링이 중요.  이러한 환경에서 데이터를 처리하는 방법을 ⇒ ETL (Extract 추출, Transform 변형, Load 적재)

적재 ≠ 저장 , 한줄 한줄 소량데이터를 저장 , 적재는 큰 많은양의 데이터를 한꺼번에 옮겨놓는 것. 

- 추출 = 어디선가 데이터를 발생시킨다. ex) 크롤링 → Extract 어디선가 데이터를 가지고 옴. 추출된 데이터의 자료형 변환 등을 수행(필요한 부분을 뽑아낸다던가) → Transform, 변환된 데이터를 저장(적재) → Load /  공백문자제거, 정규식을 이용해서 필요한 부분만 추출 한다던가 등등.

- 현재 데이터 운용방식
    - 데이터 추출(Extract) > 일단 저장(Load) = Lake > 쓰임새에 따라 변환(Transform) = Warehouse

- RDBMS 정형, 비정형-이미지,자연어,텍스트처 데이터의 저장에 따라 달라지게 됨.

# Spark

- 스파크 설치시 pip 버전과 $SPARK_HOME에 있는 버전, 다운로드한 파일 버전 맞춰줘야 함.
- 스파크 실행코드 : pyspark

### MPP
- ‘스케일업 > MPP >스케일 아웃’ 사이에 MPP가 생김.
- MPP 인력, 시간, 돈 많이들어감.  데이터가 계속 쌓이면 쪼개놓은 애들도 덩치 커지기 시작함.
  
### Yahoo의 Hadoop
- 맵리듀스를 이용해서 집계를 함. 맵리듀스만 하기에는 데이터 분석가들이 자바프로그래밍을 다 해야하니까 힘들다. 그래서 등장한게 하이브 
  
### 처리해야 될 데이터가 많을 때
- swap 안됨
- 램에 올리고 내리고 반복
- 하둡은 데이터 쪼개서 저장
- 스파크는 쪼개진 데이터를 메모리로 올려서 연산

### 데이터를 쪼개서 처리하기
네임노드에 스파크 마스터, 
데이터노드들에 워커 설치 
데이터노드와 워커가 같은 컴퓨터였음.
네트워크로 주고받고 하는거보다 훨씬 빠르게 데이터 처리가능.
보통 분산처리 스파크환경은 이렇게 구성함

- 워커들끼리 데이터 조인할때는 네트워크로 탐. 최대한 네트워크를 줄일 수 있는 방향으로 분석
- 분석은 안할거지만 실제 분산처리 환경에서 하는거처럼 코딩을 할 것. 위 그림을 잊어버리지 말고 잘 기억하기. 스파크 활용한 데이터분석, 머신러닝 할때 반드시 실무에서 참고해야할 그림임!
- 최대한 많은 작업이 워커 내부에서 일어나게 하는게 좋다. 어쩔수없는 경우에 다른노드의 데이터 가져오거나 교환할 수는 있다.

### 스파크의 클러스터(Cluster)
- 스파크의 시작은 스파크 컨텍스트부터.
- 속도를 고려하면 판다스가 훨씬 나음. 스파크는 대용량데이터를 처리하는부분에 치중했기 때문에 속도가 느릴 수 밖에 없ㅇ음. 스파크는 대용량 데이터에 대한 수평적 확장성을 고려.
- 소규모 비즈니스 로직만 보고싶다면 판다스 사용

### RDD
- HA 데이터의 고가용성 : 하나 죽어도 다른클러스터들이 작업완
- 데이터 불변성에 대한 이야기
- 자료 p.89 변경사항이 적용된 새로운 RDD가 만들어짐. (Immutable)
- 판다스는 연산이 즉시 실행
- 스파크는 연산이 직접 바로일어나지 않음. 즉각적이지 X 새로 만들어진 RDD는 실제 연산이 진행(수행)된 게 아님. **연산의 기록이 남음.**
- RDD1 (10,20,30) → +1 → RDD2(RDD1+1) →*3→RDD3(RDD2*3)
- 판다스는 (10,20,30) →+1→ (11,21,31)
- 🔴RDD는 실제 데이터세트라기보다는 대부분의 변환과정, **Trasnformation은 연산의 기록만 남는다.**
    
    이 부분을 알고있어야 효과적으로 스파크를 사용할 수 있음.

### Resilient & Immutable
- p.90 🔴연산의 수행 기록을 계속 쌓으면 일자형태의 그래프가 됨. ⇒ **Directly Acyclic Graph 비 순환 그래프** , 순환되지않고 한쪽 방향으로만, 작업의 **시작과 끝이 있음.** RDD 이 그래프를 ⇒ **DAG** 라고 부름.
- 노드나 클러스터에 문제 생겼을때 DAG 로 작업 빠꾸가넝한.
- 문제상황시 장애에 탄력적이다. ⇒ 분산환경 데이터세트인데 , 노드에서 문제 생기면 끊어진 지점부터 다시 이어서 가능. RDD (Resilient Distributed Dataset)
- p96우리는 파이썬이라 해당되지 않음

### RDD (Resilient Distributed Dataset)
- p.98 🔴🔴🔴**게으른 연산**, 결과가 실제로 사람에게 필요할때까지 연산하지 않음.(lazy) 액션이 떨어지면 연산을 시작, 연산이 직접적으로 되지 않음. Transformation 변환과 Action이 따로 분리되어있음. Action을 수행 할 때 까지는 Transformation은 실행되지 않음.
- Why? 메모리/용량 줄이려고. Action할때 시간이 오래걸리지 그전까지는 시간이 오래걸리지 않음.
- 주피터노트북 켬
- 데이터 csv 파일 다운받고, data 폴더에 업로드. 

